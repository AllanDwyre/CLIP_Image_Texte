{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ca2dae6",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">Projet CLIP</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4ab9bd",
   "metadata": {},
   "source": [
    "# Installations & Préparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47583e61",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[32m      2\u001b[39m drive.mount(\u001b[33m'\u001b[39m\u001b[33m/content/gdrive\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1f9c095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 3] The system cannot find the path specified: '/content/gdrive/My Drive/Colab Notebooks/ML_FDS'\n",
      "c:\\Users\\allan\\Desktop\\projet_clip\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "my_local_drive='/content/gdrive/My Drive/Colab Notebooks/ML_FDS'\n",
    "sys.path.append(my_local_drive)\n",
    "%cd $my_local_drive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e72703",
   "metadata": {},
   "source": [
    "## Bibliothèque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0917bd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.20.0-cp311-cp311-win_amd64.whl.metadata (4.6 kB)\n",
      "Collecting keras\n",
      "  Using cached keras-3.13.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Getting requirements to build wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [15 lines of output]\n",
      "      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "      rather than 'sklearn' for pip commands.\n",
      "      \n",
      "      Here is how to fix this error in the main use cases:\n",
      "      - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "      - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "      - if the 'sklearn' package is used by one of your dependencies,\n",
      "        it would be great if you take some time to track which package uses\n",
      "        'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "      - as a last resort, set the environment variable\n",
      "        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "      \n",
      "      More information is available at\n",
      "      https://github.com/scikit-learn/sklearn-pypi-package\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "ERROR: Failed to build 'sklearn' when getting requirements to build wheel\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'requests'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrandom\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mzipfile\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrequests\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mio\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmath\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'requests'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import random\n",
    "import zipfile\n",
    "import requests\n",
    "import io\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras.utils import register_keras_serializable\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.metrics import Mean\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Pour utiliser au mieux le GPU\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146b79f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.lirmm.fr/~poncelet/Ressources/flickr_subset2.zip\"\n",
    "target_dir = \"flickr_subset2\"\n",
    "\n",
    "# Vérifie si le dossier existe déjà\n",
    "if os.path.exists(target_dir) and os.path.isdir(target_dir):\n",
    "    print(\"Données déjà disponibles dans :\", target_dir)\n",
    "else:\n",
    "    print(\"Téléchargement de flickr_subset2.zip...\")\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        print(\"Téléchargement réussi. Extraction...\")\n",
    "        with zipfile.ZipFile(io.BytesIO(response.content)) as zip_ref:\n",
    "            # Extraire sans ajouter de sous-dossier supplémentaire\n",
    "            for member in zip_ref.namelist():\n",
    "                # Corrige les chemins pour ignorer un éventuel prefixe flickr_subset2/\n",
    "                member_path = member\n",
    "                if member.startswith(\"flickr_subset2/\"):\n",
    "                    member_path = member[len(\"flickr_subset2/\"):]\n",
    "                target_path = os.path.join(target_dir, member_path)\n",
    "\n",
    "                # Si c'est un répertoire, on le crée\n",
    "                if member.endswith(\"/\"):\n",
    "                    os.makedirs(target_path, exist_ok=True)\n",
    "                else:\n",
    "                    os.makedirs(os.path.dirname(target_path), exist_ok=True)\n",
    "                    with zip_ref.open(member) as source, open(target_path, \"wb\") as target:\n",
    "                        target.write(source.read())\n",
    "        print(f\"Données extraites dans : {target_dir}\")\n",
    "    else:\n",
    "        print(\"Échec du téléchargement. Code HTTP :\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daab4665",
   "metadata": {},
   "source": [
    "## Fonctions et Classes utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49b0e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FONCTIONS UTILES\n",
    "\n",
    "def preview_images_from_dir(image_dir, image_size=(224, 224), n=12,\n",
    "                            subset=\"training\", seed=123):\n",
    "    \"\"\"\n",
    "    Affiche n images avec leurs labels à partir d'un dossier\n",
    "    (flow_from_directory).\n",
    "    N'utilise PAS train_gen pour ne pas en avancer l'index.\n",
    "    \"\"\"\n",
    "    # Générateur léger juste pour l'aperçu\n",
    "    # Ici il y a une bonne indication si vous regardez bien pour la classif :)\n",
    "    preview_datagen = ImageDataGenerator(validation_split=0.2, rescale=1./255)\n",
    "\n",
    "    preview_gen = preview_datagen.flow_from_directory(\n",
    "        image_dir,\n",
    "        target_size=image_size,\n",
    "        batch_size=n,\n",
    "        class_mode=\"categorical\",\n",
    "        subset=subset,\n",
    "        shuffle=True,\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "    imgs, y = next(preview_gen)    # imgs: (n, H, W, 3), y: one-hot\n",
    "    class_names = list(preview_gen.class_indices.keys())\n",
    "    labels = np.argmax(y, axis=1)\n",
    "\n",
    "    rows = 3\n",
    "    cols = int(np.ceil(n / rows))\n",
    "    plt.figure(figsize=(4*cols, 4*rows))\n",
    "    for i in range(min(n, imgs.shape[0])):\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        plt.imshow(imgs[i])\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8f6d0b",
   "metadata": {},
   "source": [
    "# Réaliser un classifieur d’images pour les 4 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a3e1ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
